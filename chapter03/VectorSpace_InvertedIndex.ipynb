{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Space retrieval with inverted files\n",
    "\n",
    "## Helper functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TopKList class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappop, heappush, nsmallest\n",
    "from typing import Callable\n",
    "\n",
    "class TopKList:\n",
    "    \"\"\"\n",
    "        Maintains a list of top-k documents. Initializer accepts\n",
    "        a list of tuples (term, weight) to provide information about\n",
    "        weights used by retrieval model. Implements the iter() interface.\n",
    "        Takes an optional predicate(doc_id: int) function to filter documents\n",
    "        before returning them. \n",
    "    \"\"\"\n",
    "    def __init__(self, k: int, term_weights: list[tuple[str,float]] = None, predicate: Callable[[int], bool] = None):\n",
    "        self.docs_heap = []\n",
    "        self.k = k\n",
    "        self.predicate = predicate\n",
    "        if term_weights:\n",
    "            self.term_weights = term_weights\n",
    "            self.terms = [term for term, _ in self.term_weights]\n",
    "            self.weights = dict(self.term_weights)\n",
    "    \n",
    "    def add(self, doc_id: int, score: float):\n",
    "        heappush(self.docs_heap, (-score, doc_id, {'id': doc_id, 'score': score}))\n",
    "        # optional (infrequent) pruning if heap grows too large\n",
    "\n",
    "    def __iter__(self):\n",
    "        rank = 0\n",
    "        while rank < self.k and len(self.docs_heap) > 0:\n",
    "            entry = heappop(self.docs_heap)[2]\n",
    "            if self.predicate == None or self.predicate(entry['id']):\n",
    "                rank += 1\n",
    "                entry['rank'] = rank\n",
    "                yield entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def idf(doc_freq: int, num_docs: int) -> float:\n",
    "    return math.log((num_docs + 1) / (doc_freq + 1))\n",
    "\n",
    "def idf_bm25(doc_freq: int, num_docs: int) -> float:\n",
    "    return math.log((num_docs - doc_freq + 0.5) / (doc_freq + 0.5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for pretty printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to display result and get feedback\n",
    "def print_topk(topk):\n",
    "    global documents\n",
    "    print(\"\\n    r  id score  document\\n-------------------------------------\")\n",
    "    for entry in topk:\n",
    "        print(\"  {rank: >3d} {id: >3d} ({score:.2f})\".format(**entry), documents[entry['id']])\n",
    "    print()\n",
    "    for term in sorted(topk.weights.keys(), key = lambda term: -topk.weights[term]):\n",
    "        print(term.rjust(16), topk.weights[term])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Space Model Implementation\n",
    "\n",
    "### Scoring functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VSMeasure: pass\n",
    "    \n",
    "# implements the cosine measure\n",
    "class CosineMeasure(VSMeasure):\n",
    "\n",
    "    def __init__(self, query_vector: dict[str, int]):\n",
    "        self.query_vector_normalized = {}\n",
    "        self.term_weights = []\n",
    "        self.query_norm = 0\n",
    "        for term in query_vector.keys():\n",
    "            if term in vocabulary:\n",
    "                idf_2 = vocabulary[term]['idf'] ** 2\n",
    "                self.query_vector_normalized[term] = query_vector[term] * idf_2\n",
    "                self.term_weights.append((term, vocabulary[term]['idf']))\n",
    "                self.query_norm += idf_2 * query_vector[term] ** 2\n",
    "        self.query_norm = self.query_norm ** 0.5\n",
    "        for term in self.query_vector_normalized.keys():\n",
    "            self.query_vector_normalized[term] /= self.query_norm\n",
    "    \n",
    "    def similarity(self, doc_id: int, doc_vector: dict[str, int] = None):\n",
    "        if not doc_vector: \n",
    "            doc_vector = documents[doc_id]['vector']\n",
    "        dot_product = sum([doc_vector.get(term, 0) * q for (term, q) in self.query_vector_normalized.items()])\n",
    "        return dot_product / documents[doc_id]['norm']\n",
    "\n",
    "# implements the dot product\n",
    "class DotProduct(VSMeasure):\n",
    "    def __init__(self, query_vector: dict[str, int]):\n",
    "        self.query_vector_idf2 = {}\n",
    "        self.term_weights = []\n",
    "        for term in query_vector.keys():\n",
    "            if term in vocabulary:\n",
    "                idf = vocabulary[term]['idf']\n",
    "                self.query_vector_idf2[term] = query_vector[term] * idf ** 2\n",
    "                self.term_weights.append((term, idf))\n",
    "    \n",
    "    def similarity(self, doc_id: int, doc_vector: dict[str, int] = None):\n",
    "        if not doc_vector:\n",
    "            doc_vector = documents[doc_id]['vector']\n",
    "        dot_product = sum([doc_vector.get(term, 0) * q for (term, q) in self.query_vector_idf2.items()])\n",
    "        return dot_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class VSModel:\n",
    "    \"\"\"\n",
    "        Generic class for the evaluation of the Vector Space model, inherited by the document-at-a-time (DAAT) and \n",
    "        term-at-a-time (TAAT) implementation. This superclass defines the idf-weights including filtering the most\n",
    "        important terms.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def get_similarity_measure(measure: str, query_vector: dict[str, int]) -> VSMeasure:\n",
    "        return {\n",
    "            'cosine': CosineMeasure(query_vector)\n",
    "        }[measure]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-at-a-time for Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VSModel_DAAT(VSModel):\n",
    "    \"\"\"\n",
    "        Implements the DAAT model for the Vector Space model using inverted index method.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def query(query_vector: dict[str, int], k: int, measure: str = 'dot', predicate: Callable[[int], bool] = None, selected_docs: set[int] = None):\n",
    "        # determine simialrity measure for this query\n",
    "        sim = VSModel.get_similarity_measure(measure, query_vector)\n",
    "        \n",
    "        # get iterators for each term and fetch first posting; postings have form (term, tf)\n",
    "        iters = [iter(index[term]) for (term, _) in sim.term_weights]\n",
    "        nexts = [next(iter, None) for iter in iters]\n",
    "\n",
    "        # keep track of all retrieved documents and their score; stored as tuples (doc_id, score)\n",
    "        topk = TopKList(k, sim.term_weights, predicate)\n",
    "        while not all(e is None for e in nexts):\n",
    "            # get smallest value from nexts, ignoring None values\n",
    "            smallest = min(nexts, key = lambda x: x[0] if x is not None else float('inf'))[0]\n",
    "            # create a document vector with only the query terms for the document with id = smallest\n",
    "            doc_query_terms = {sim.term_weights[i][0]: nexts[i][1] for i in range(len(nexts)) if nexts[i] and nexts[i][0] == smallest}\n",
    "            score = sim.similarity(smallest, doc_query_terms)\n",
    "            # assert score == sim.similarity(smallest)\n",
    "            topk.add(smallest, score)\n",
    "            # for each entry in nexts, fetch next item if entry equals smallest\n",
    "            for i, e in enumerate(nexts):\n",
    "                if e and e[0] is smallest:\n",
    "                    nexts[i] = next(iters[i], None)\n",
    "        \n",
    "        # finsihed, return topk for result iteration\n",
    "        return topk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term-at-a-time for Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random data example\n",
    "### Create inverted index\n",
    "The next section generates random inverted index postings for a set of terms. It simulates the indexing process for Boolean retrieval by associating random document IDs with each term. The `vocabulary` dictionary defines terms and their desired document frequencies (as a %-figure). The generated postings are stored in the `index` dictionary, with each term mapped to a set of corresponding document IDs.\n",
    "\n",
    "* `nDocs = 100`: Defines the total number of documents (document IDs) as 100.\n",
    "* `index = {}`: Initializes an empty dictionary to store the postings for each term.\n",
    "* `DEBUG = False`: A debug flag (we use it later to illustrate code execution).\n",
    "* `vocabulary`: Defines a dictionary where each term is associated with its desired document frequency (expressed as a percentage).\n",
    "* `documents`: List of all documents with each entry holding a dictionary {vector: dict, len: float, norm: float}\n",
    "  - vector holds the term freqeuncies as dictionary (key=term, value=term frequency)\n",
    "  - len is the number of terms in the document (its length)\n",
    "  - norm is the \n",
    "\n",
    "`create_postings(term: str, docFreq: int = None)` takes a term (string) and an optional document frequency (docFreq, integer) as arguments. It generates random postings for the term by creating a set of document IDs. If docFreq is not provided, it generates a random document frequency between 1 and nDocs. The for-loop iterates through each term in the vocabulary dictionary and calls the create_postings function. For each term, it fetches the desired document frequency from the vocabulary (values are percentages) and passes it to create_postings.\n",
    "\n",
    "`is_relevant(doc_id: int)` returns True if document is relevant ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "DEBUG = False\n",
    "nDocs = 40\n",
    "index = {}\n",
    "documents = {}\n",
    "vocabulary = {}\n",
    "\n",
    "# helper function to create random postings with given document frequency\n",
    "def create_postings(term: str, docFreq: int = None):\n",
    "    # create sets with random ids\n",
    "    index[term] = []\n",
    "    vocabulary[term] = {'df': docFreq, 'idf': 0}\n",
    "    # extend feature vectors for documents with a random term frequency\n",
    "    for doc_id in sorted(random.sample(sorted(documents.keys()), docFreq)):\n",
    "        # select a random term frequency for the term\n",
    "        tf = random.randint(1, 10)\n",
    "        index[term].append((doc_id, tf))\n",
    "        documents[doc_id]['vector'][term] = tf\n",
    "\n",
    "# set all feature vectors of documents to empty. We use sets since BIR uses set-of-word model\n",
    "for doc_id in range(1, nDocs + 1):\n",
    "    documents[doc_id] = {'id': doc_id, 'vector': {}, 'len': 0, 'norm': 0}\n",
    "\n",
    "# we use some animal terms to create random documents\n",
    "terms = ['dog', 'cat', 'horse', 'rabit', 'ostrich', 'bear', 'tiger', 'lion', 'bird']\n",
    "\n",
    "# call create_postings for each entry in vocabulary to create the inverted index\n",
    "for term in terms:\n",
    "    create_postings(term, random.randint(nDocs // 10, nDocs // 2))\n",
    "\n",
    "# now calculate the idf for each term and the norm for each document\n",
    "for item in vocabulary.values():\n",
    "    item['idf'] = idf(item['df'], nDocs)\n",
    "    item['idf_bm25'] = idf_bm25(item['df'], nDocs)\n",
    "for doc in documents.values():\n",
    "    doc['len'] = sum([tf for _, tf in doc['vector'].items()])\n",
    "    doc['norm'] = sum([(tf * vocabulary[term]['idf']) ** 2 for term, tf in doc['vector'].items()]) ** 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the postings for each term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog        9    1.41    1.20    [(7, 8), (16, 2), (17, 7), (21, 8), (22, 2), (26, 4), (31, 9), (34, 9), (38, 9)]\n",
      "cat        15   0.94    0.50    [(2, 5), (3, 7), (4, 8), (6, 2), (13, 1), (15, 9), (18, 3), (22, 3), (26, 6), (28, 10), (30, 6), (31, 10), (36, 4), (39, 8), (40, 8)]\n",
      "horse      11   1.23    0.94    [(4, 8), (9, 2), (11, 8), (14, 5), (17, 9), (19, 1), (20, 10), (27, 9), (35, 10), (37, 6), (39, 10)]\n",
      "rabit      5    1.92    1.86    [(4, 10), (20, 10), (28, 6), (30, 7), (31, 1)]\n",
      "ostrich    14   1.01    0.60    [(2, 9), (9, 3), (10, 5), (12, 5), (15, 1), (17, 7), (20, 1), (21, 9), (23, 7), (26, 6), (27, 4), (29, 2), (33, 10), (37, 2)]\n",
      "bear       15   0.94    0.50    [(2, 3), (5, 2), (7, 2), (9, 7), (14, 6), (16, 4), (19, 7), (20, 4), (23, 3), (24, 9), (25, 6), (28, 4), (31, 2), (38, 9), (39, 3)]\n",
      "tiger      8    1.52    1.34    [(10, 5), (13, 6), (16, 5), (22, 3), (30, 7), (32, 6), (37, 4), (38, 9)]\n",
      "lion       12   1.15    0.82    [(1, 5), (2, 6), (9, 2), (12, 5), (16, 10), (17, 6), (22, 9), (27, 2), (30, 4), (32, 5), (34, 7), (39, 7)]\n",
      "bird       11   1.23    0.94    [(3, 4), (4, 2), (10, 9), (13, 5), (19, 9), (30, 5), (32, 1), (36, 6), (37, 1), (38, 2), (40, 7)]\n"
     ]
    }
   ],
   "source": [
    "# print vocabulary with df and idf\n",
    "for term, item in vocabulary.items():\n",
    "    print(\"{term:10} {df:<4d} {idf:<7.2f} {idf_bm25:<7.2f} {postings}\".format(term=term.ljust(10), df=item['df'], idf=item['idf'], idf_bm25=item['idf_bm25'], postings=index[term]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 | 5     5.74    {'lion': 5}\n",
      "   2 | 23    12.63   {'cat': 5, 'ostrich': 9, 'bear': 3, 'lion': 6}\n",
      "   3 | 11    8.22    {'cat': 7, 'bird': 4}\n",
      "   4 | 28    22.99   {'cat': 8, 'horse': 8, 'rabit': 10, 'bird': 2}\n",
      "   5 | 2     1.88    {'bear': 2}\n",
      "   6 | 2     1.88    {'cat': 2}\n",
      "   7 | 10    11.44   {'dog': 8, 'bear': 2}\n",
      "   8 | 0     0.00    {}\n",
      "   9 | 14    7.99    {'horse': 2, 'ostrich': 3, 'bear': 7, 'lion': 2}\n",
      "  10 | 19    14.32   {'ostrich': 5, 'tiger': 5, 'bird': 9}\n",
      "  11 | 8     9.83    {'horse': 8}\n",
      "  12 | 10    7.63    {'ostrich': 5, 'lion': 5}\n",
      "  13 | 12    11.02   {'cat': 1, 'tiger': 6, 'bird': 5}\n",
      "  14 | 11    8.34    {'horse': 5, 'bear': 6}\n",
      "  15 | 10    8.53    {'cat': 9, 'ostrich': 1}\n",
      "  16 | 21    14.54   {'dog': 2, 'bear': 4, 'tiger': 5, 'lion': 10}\n",
      "  17 | 29    17.80   {'dog': 7, 'horse': 9, 'ostrich': 7, 'lion': 6}\n",
      "  18 | 3     2.82    {'cat': 3}\n",
      "  19 | 17    12.93   {'horse': 1, 'bear': 7, 'bird': 9}\n",
      "  20 | 25    23.14   {'horse': 10, 'rabit': 10, 'ostrich': 1, 'bear': 4}\n"
     ]
    }
   ],
   "source": [
    "# print a few documents\n",
    "for doc_id in range(1, 21):\n",
    "    print(\"{id:>4} | {len:<5d} {norm:<7.2f} {terms}\".format(id=doc_id, len=documents[doc_id]['len'], norm=documents[doc_id]['norm'], terms=str(documents[doc_id]['vector'])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bird': 2, 'horse': 1}\n",
      "\n",
      "    r  id score  document\n",
      "-------------------------------------\n",
      "    1  19 (0.81) {'id': 19, 'vector': {'horse': 1, 'bear': 7, 'bird': 9}, 'len': 17, 'norm': 12.929646825221669}\n",
      "    2  36 (0.80) {'id': 36, 'vector': {'cat': 4, 'bird': 6}, 'len': 10, 'norm': 8.277286265141177}\n",
      "    3  10 (0.69) {'id': 10, 'vector': {'ostrich': 5, 'tiger': 5, 'bird': 9}, 'len': 19, 'norm': 14.319172933962935}\n",
      "    4  40 (0.67) {'id': 40, 'vector': {'cat': 8, 'bird': 7}, 'len': 15, 'norm': 11.42978978465472}\n",
      "    5   3 (0.53) {'id': 3, 'vector': {'cat': 7, 'bird': 4}, 'len': 11, 'norm': 8.218329050423852}\n",
      "    6  13 (0.50) {'id': 13, 'vector': {'cat': 1, 'tiger': 6, 'bird': 5}, 'len': 12, 'norm': 11.018215228846154}\n",
      "    7  11 (0.45) {'id': 11, 'vector': {'horse': 8}, 'len': 8, 'norm': 9.829323335330459}\n",
      "    8  35 (0.45) {'id': 35, 'vector': {'horse': 10}, 'len': 10, 'norm': 12.286654169163073}\n",
      "    9  37 (0.45) {'id': 37, 'vector': {'horse': 6, 'ostrich': 2, 'tiger': 4, 'bird': 1}, 'len': 13, 'norm': 9.833063834527302}\n",
      "   10  27 (0.41) {'id': 27, 'vector': {'horse': 9, 'ostrich': 4, 'lion': 2}, 'len': 15, 'norm': 11.988896501047607}\n",
      "\n",
      "            bird 1.2286654169163074\n",
      "           horse 1.2286654169163074\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "\n",
    "# initial step for \"bird(2) horse\"\n",
    "query = {'bird': 2, 'horse':1}\n",
    "k = 10\n",
    "print(query)\n",
    "\n",
    "# (optional) enable a predicate for the filtering step\n",
    "predicate = None\n",
    "# predicate = lambda doc_id: doc_id % 2 == 0\n",
    "# predicate = lambda doc_id: doc_id % 2 == 1\n",
    "selected_docs = None\n",
    "# selected_docs = list(range(10))\n",
    "\n",
    "# run query, display result, and get feedback\n",
    "topk = VSModel_DAAT.query(query, k, 'cosine', predicate)\n",
    "print_topk(topk)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Search Example\n",
    "### Load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import stopwords\n",
    "import re\n",
    "\n",
    "def build_index(data):\n",
    "    global nDocs, index, documents, vocabulary\n",
    "    nDocs = len(data)\n",
    "    index = {}\n",
    "    documents = {}\n",
    "    vocabulary = {}\n",
    "    all_terms = []\n",
    "    for doc in data:\n",
    "        documents[doc['id']] = doc\n",
    "        # get terms from all string properties of doc\n",
    "        text = ' '.join([value for key, value in doc.items() if type(value) == str])\n",
    "        text = re.sub(r'[,\\.\\-\\?!\\(\\)\\s:;_\\'\"\\+\\*\\&\\$]', ' ', text.lower())\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        terms = filter(lambda t: t not in stopwords.english, text.split(' '))\n",
    "        # create bag-of-words vector (dict)\n",
    "        doc['vector'] = dict([(term, len(list(group))) for term, group in groupby(sorted(terms))])\n",
    "        doc['len'] = sum([tf for _, tf in doc['vector'].items()])\n",
    "        # update vocabulary (holding df values) and index (term -> postings)\n",
    "        for term, tf in doc['vector'].items():\n",
    "            vocabulary[term] = vocabulary.get(term, 0) + 1\n",
    "            index[term] = index.get(term, []) + [(doc['id'], tf)]\n",
    "    # update vocabulary -> create dict with df, idf, and idf_bm25 values\n",
    "    vocabulary = dict([(term, {'df': df, 'idf': idf(df, nDocs), 'idf_bm25': idf_bm25(df, nDocs)}) for term, df in vocabulary.items()])\n",
    "    # calculate norm of vector for cosine measure\n",
    "    for doc in documents.values():\n",
    "        doc['norm'] = sum([(tf * vocabulary[term]['idf']) ** 2 for term, tf in doc['vector'].items()]) ** 0.5        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'title': 'The Shawshank Redemption',\n",
       "  'year': 1994,\n",
       "  'runtime': 142,\n",
       "  'rating': 9.3,\n",
       "  'genre': 'Drama',\n",
       "  'actors': 'Tim Robbins Morgan Freeman Bob Gunton William Sadler',\n",
       "  'summary': 'Two imprisoned men bond over a number of years, finding solace and eventual redemption through acts of common decency.'}]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the imdb data set (1000 movies)\n",
    "from datasets.docs import imdb\n",
    "from utils import stopwords\n",
    "\n",
    "data = imdb.load()\n",
    "data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDocs = 1000, nTerms = 9900, nPostings\n"
     ]
    }
   ],
   "source": [
    "build_index(data)\n",
    "print('nDocs = {nDocs}, nTerms = {nTerms}, nPostings'.format(nDocs=nDocs, nTerms=len(vocabulary), nPostings=sum([len(postings) for postings in index.values()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term               df     idf idf_bm25    postings\n",
      "----------------------------------------------------------------------------------------------------\n",
      "drama             724    0.32    -0.96    [(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (10, 1), (11, 1), (12, 1), (14, 1), (16, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (43, 1), (44, 1), (46, 1), (47, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (60, 1), (63, 1), (65, 1), (66, 1), (68, 1), (69, 1), (72, 1), (74, 1), (75, 1), (77, 1), (78, 1), (80, 1), (81, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (98, 1), (99, 1), (100, 1), (101, 1), (103, 1), (104, 1), (105, 1), (106, 1), (108, 1), (109, 1), (111, 1), (112, 1), (113, 1), (114, 1), (117, 1), (118, 1), (122, 1), (123, 1), (124, 1), (125, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (137, 1), (138, 1), (139, 1), (140, 1), (142, 1), (144, 1), (145, 1), (148, 1), (149, 1), (150, 1), (151, 1), (153, 1), (154, 1), (155, 1), (157, 1), (158, 1), (160, 1), (163, 1), (164, 1), (165, 1), (166, 1), (168, 1), (170, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 2), (180, 1), (181, 1), (182, 1), (183, 1), (185, 1), (186, 1), (187, 1), (189, 1), (190, 1), (191, 1), (192, 1), (194, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (207, 1), (208, 1), (209, 1), (211, 1), (212, 1), (213, 1), (215, 1), (216, 1), (217, 1), (218, 1), (219, 1), (220, 1), (222, 1), (223, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (232, 1), (233, 1), (234, 1), (235, 1), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (244, 1), (245, 1), (247, 1), (248, 1), (249, 1), (250, 1), (251, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 1), (260, 1), (261, 1), (262, 1), (264, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (273, 1), (274, 1), (275, 1), (277, 1), (279, 1), (280, 1), (281, 1), (282, 1), (283, 1), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (296, 1), (297, 1), (298, 1), (299, 1), (300, 1), (301, 1), (302, 1), (303, 1), (304, 1), (305, 1), (306, 1), (307, 1), (308, 1), (309, 1), (311, 1), (312, 1), (313, 1), (314, 1), (315, 1), (316, 1), (318, 1), (320, 1), (323, 1), (324, 1), (325, 1), (328, 1), (329, 1), (330, 1), (332, 1), (333, 1), (334, 1), (335, 1), (336, 1), (337, 1), (339, 1), (341, 1), (342, 1), (343, 1), (344, 1), (345, 1), (346, 1), (347, 1), (348, 1), (350, 1), (351, 1), (352, 1), (353, 1), (354, 1), (355, 1), (356, 1), (357, 1), (359, 1), (360, 1), (361, 1), (362, 1), (364, 1), (366, 1), (371, 1), (372, 1), (373, 1), (374, 1), (375, 1), (376, 1), (378, 1), (380, 1), (381, 1), (382, 1), (383, 1), (384, 1), (385, 1), (386, 1), (388, 1), (389, 1), (392, 1), (393, 1), (398, 1), (399, 1), (401, 1), (403, 1), (404, 1), (405, 1), (408, 1), (409, 1), (410, 1), (412, 1), (413, 1), (414, 1), (417, 1), (419, 1), (422, 1), (423, 1), (424, 1), (425, 1), (426, 1), (428, 1), (429, 1), (430, 1), (431, 1), (432, 1), (433, 1), (434, 1), (435, 1), (436, 1), (437, 1), (438, 1), (439, 1), (440, 1), (441, 1), (442, 1), (443, 1), (444, 1), (445, 1), (446, 1), (448, 1), (449, 1), (451, 1), (452, 1), (453, 1), (454, 1), (455, 1), (458, 1), (460, 1), (462, 1), (463, 1), (464, 1), (465, 1), (466, 1), (467, 1), (468, 1), (469, 1), (471, 1), (472, 1), (473, 1), (475, 1), (476, 1), (477, 1), (479, 1), (481, 1), (482, 1), (484, 1), (485, 1), (486, 1), (487, 1), (488, 1), (490, 1), (491, 1), (492, 1), (493, 1), (495, 1), (496, 1), (497, 1), (498, 1), (499, 1), (501, 1), (502, 1), (505, 1), (506, 1), (509, 1), (510, 1), (513, 1), (514, 1), (515, 1), (516, 1), (518, 1), (519, 1), (520, 1), (521, 1), (522, 1), (524, 1), (525, 1), (526, 1), (527, 1), (528, 1), (529, 1), (530, 1), (534, 1), (535, 1), (537, 1), (538, 1), (539, 1), (542, 1), (543, 1), (546, 1), (547, 1), (549, 1), (550, 1), (551, 1), (552, 1), (553, 1), (554, 1), (555, 1), (556, 1), (558, 1), (559, 1), (560, 1), (562, 1), (564, 1), (568, 1), (571, 1), (572, 1), (573, 1), (574, 1), (575, 1), (576, 1), (578, 1), (580, 1), (581, 1), (582, 1), (585, 1), (586, 1), (588, 1), (589, 1), (590, 1), (591, 1), (594, 1), (595, 1), (596, 1), (598, 1), (599, 1), (601, 1), (602, 1), (603, 1), (604, 1), (606, 1), (607, 1), (608, 1), (611, 1), (612, 1), (613, 1), (614, 1), (615, 1), (617, 1), (618, 1), (620, 1), (621, 1), (622, 1), (623, 1), (625, 1), (626, 1), (627, 1), (629, 1), (630, 1), (631, 1), (632, 1), (633, 1), (636, 1), (637, 1), (638, 1), (639, 1), (640, 1), (641, 1), (642, 1), (643, 1), (644, 1), (645, 1), (647, 1), (648, 1), (650, 1), (651, 1), (653, 1), (654, 1), (655, 1), (656, 1), (657, 1), (658, 1), (659, 1), (660, 1), (661, 1), (662, 1), (663, 1), (664, 1), (665, 1), (668, 1), (669, 1), (670, 1), (671, 1), (672, 1), (673, 1), (674, 1), (675, 1), (677, 1), (681, 1), (683, 1), (684, 1), (685, 1), (687, 1), (688, 1), (690, 1), (691, 1), (694, 1), (696, 1), (697, 1), (698, 1), (700, 1), (702, 1), (704, 1), (706, 1), (707, 1), (709, 1), (710, 1), (711, 1), (714, 1), (717, 1), (719, 1), (720, 1), (721, 1), (722, 1), (724, 1), (727, 1), (729, 1), (730, 1), (732, 1), (733, 1), (734, 1), (735, 1), (736, 1), (737, 1), (739, 1), (740, 1), (742, 1), (743, 1), (746, 1), (748, 2), (749, 1), (753, 1), (754, 1), (755, 1), (758, 1), (759, 1), (760, 1), (761, 1), (763, 1), (764, 1), (765, 1), (766, 1), (767, 1), (768, 1), (769, 1), (770, 1), (771, 1), (773, 1), (774, 1), (775, 1), (776, 1), (779, 1), (780, 1), (781, 1), (783, 1), (784, 1), (785, 1), (786, 1), (787, 1), (788, 1), (789, 1), (790, 1), (791, 1), (792, 1), (793, 1), (794, 1), (795, 1), (799, 1), (802, 1), (803, 1), (804, 1), (805, 1), (806, 1), (807, 1), (810, 1), (811, 1), (812, 1), (813, 1), (814, 1), (815, 2), (816, 1), (818, 1), (819, 1), (820, 1), (821, 1), (822, 1), (824, 1), (825, 1), (826, 1), (827, 1), (828, 1), (831, 1), (832, 1), (833, 1), (834, 1), (835, 1), (837, 1), (839, 1), (842, 1), (846, 1), (850, 1), (851, 1), (852, 1), (853, 1), (858, 1), (859, 1), (860, 1), (861, 1), (863, 1), (864, 1), (865, 1), (867, 1), (868, 1), (869, 1), (871, 1), (872, 1), (873, 1), (874, 1), (875, 1), (878, 1), (879, 1), (880, 1), (881, 1), (882, 1), (883, 1), (884, 1), (885, 1), (886, 1), (887, 1), (889, 1), (890, 1), (891, 1), (894, 1), (895, 1), (896, 1), (897, 1), (898, 1), (899, 1), (902, 1), (904, 1), (905, 1), (906, 1), (908, 1), (911, 1), (912, 1), (914, 1), (916, 1), (917, 1), (918, 1), (919, 1), (922, 1), (923, 1), (924, 1), (925, 1), (926, 1), (927, 1), (929, 1), (930, 1), (931, 1), (932, 1), (934, 1), (935, 1), (936, 1), (937, 1), (938, 1), (939, 1), (940, 1), (941, 1), (942, 1), (943, 1), (944, 1), (945, 1), (946, 1), (947, 1), (950, 1), (951, 1), (953, 1), (954, 1), (955, 1), (956, 1), (958, 1), (959, 1), (961, 1), (963, 1), (965, 1), (966, 1), (967, 1), (968, 1), (969, 1), (972, 1), (975, 1), (976, 1), (979, 1), (981, 1), (982, 1), (987, 1), (988, 1), (989, 1), (990, 1), (991, 1), (994, 1), (996, 1), (997, 1), (998, 1), (999, 1)]\n",
      "comedy            233    1.45     1.19    [(20, 1), (27, 1), (36, 1), (48, 1), (52, 1), (53, 1), (65, 1), (79, 1), (84, 1), (96, 1), (97, 1), (102, 1), (113, 1), (118, 1), (121, 1), (128, 1), (129, 1), (132, 1), (133, 1), (136, 1), (138, 1), (141, 1), (147, 1), (152, 1), (154, 1), (161, 1), (162, 1), (167, 1), (170, 1), (178, 1), (179, 1), (184, 1), (193, 1), (194, 1), (195, 1), (205, 1), (206, 1), (208, 1), (209, 1), (210, 1), (214, 1), (215, 1), (222, 1), (230, 1), (234, 1), (239, 1), (241, 1), (243, 1), (246, 1), (251, 1), (252, 1), (253, 1), (257, 1), (262, 1), (267, 1), (278, 1), (285, 1), (295, 1), (312, 1), (314, 1), (317, 1), (319, 1), (321, 1), (323, 1), (326, 1), (328, 1), (331, 1), (340, 1), (349, 1), (367, 1), (368, 1), (375, 1), (380, 1), (382, 1), (391, 1), (393, 1), (397, 1), (400, 1), (404, 1), (414, 1), (415, 1), (418, 1), (428, 1), (436, 1), (446, 1), (447, 1), (450, 1), (456, 1), (460, 1), (461, 1), (464, 1), (465, 1), (467, 1), (470, 1), (471, 1), (472, 1), (473, 1), (474, 1), (476, 1), (482, 1), (491, 1), (495, 1), (500, 1), (501, 1), (504, 1), (510, 1), (515, 1), (517, 1), (527, 1), (529, 1), (531, 1), (532, 1), (533, 1), (534, 1), (539, 1), (540, 1), (542, 1), (548, 1), (558, 1), (559, 1), (563, 1), (564, 1), (566, 1), (570, 1), (575, 1), (577, 1), (588, 1), (592, 1), (594, 1), (595, 1), (597, 1), (599, 1), (601, 1), (614, 1), (627, 1), (628, 1), (631, 1), (634, 1), (641, 1), (652, 1), (658, 1), (661, 1), (663, 1), (668, 1), (676, 1), (679, 1), (680, 1), (681, 1), (682, 1), (684, 1), (686, 1), (688, 2), (702, 1), (705, 1), (712, 1), (716, 1), (718, 1), (723, 1), (727, 1), (728, 1), (731, 1), (733, 1), (734, 1), (740, 1), (741, 1), (744, 1), (751, 1), (753, 1), (755, 2), (757, 1), (761, 1), (762, 1), (772, 1), (777, 1), (781, 1), (787, 1), (790, 1), (795, 1), (798, 1), (799, 1), (800, 1), (801, 1), (802, 1), (804, 1), (806, 1), (807, 1), (809, 1), (815, 1), (816, 1), (817, 1), (818, 1), (820, 1), (823, 1), (827, 1), (829, 1), (831, 1), (836, 1), (837, 1), (838, 1), (843, 1), (847, 1), (849, 1), (856, 1), (870, 1), (871, 1), (872, 1), (880, 1), (885, 1), (888, 1), (893, 1), (898, 1), (907, 1), (908, 2), (909, 1), (913, 1), (936, 1), (938, 1), (946, 1), (954, 1), (958, 1), (968, 1), (970, 1), (971, 1), (973, 2), (974, 1), (976, 1), (978, 1), (979, 1), (985, 1), (990, 1), (992, 1), (995, 1), (996, 1)]\n",
      "crime             215    1.53     1.29    [(2, 2), (3, 1), (4, 2), (5, 1), (7, 1), (16, 2), (23, 1), (26, 1), (28, 1), (29, 1), (34, 2), (38, 1), (42, 1), (43, 1), (54, 1), (56, 1), (72, 1), (78, 1), (80, 1), (87, 2), (88, 2), (97, 1), (104, 1), (109, 1), (112, 1), (113, 1), (114, 1), (124, 1), (126, 1), (133, 1), (134, 1), (137, 2), (141, 1), (143, 1), (148, 2), (154, 1), (156, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 1), (170, 2), (181, 1), (187, 2), (188, 1), (190, 1), (197, 1), (199, 1), (202, 1), (210, 1), (219, 1), (223, 1), (225, 1), (233, 1), (240, 1), (242, 1), (244, 1), (252, 1), (253, 1), (256, 2), (258, 1), (262, 1), (264, 1), (285, 1), (288, 1), (289, 1), (295, 1), (299, 1), (300, 2), (306, 1), (309, 1), (327, 1), (333, 1), (336, 1), (338, 1), (346, 1), (357, 1), (364, 1), (365, 1), (370, 1), (376, 1), (381, 1), (385, 1), (387, 1), (391, 1), (395, 1), (398, 1), (417, 1), (419, 1), (425, 1), (438, 1), (439, 1), (442, 1), (443, 1), (445, 1), (450, 1), (451, 2), (452, 1), (456, 1), (461, 1), (464, 1), (466, 1), (475, 2), (481, 1), (485, 1), (486, 1), (488, 1), (495, 1), (506, 1), (511, 1), (513, 1), (520, 1), (521, 1), (524, 1), (528, 1), (547, 1), (557, 1), (561, 1), (570, 1), (578, 1), (585, 1), (587, 1), (598, 1), (603, 1), (604, 1), (605, 1), (606, 1), (608, 1), (609, 1), (612, 1), (621, 1), (622, 1), (623, 1), (631, 1), (640, 1), (649, 1), (654, 1), (664, 1), (665, 1), (666, 1), (667, 1), (670, 1), (675, 1), (677, 1), (681, 1), (688, 1), (696, 1), (697, 1), (703, 2), (709, 1), (711, 1), (719, 1), (724, 1), (760, 1), (763, 1), (764, 1), (768, 1), (769, 2), (775, 1), (776, 1), (783, 1), (792, 1), (796, 1), (798, 1), (803, 1), (810, 1), (812, 1), (815, 2), (824, 1), (828, 2), (834, 1), (837, 1), (848, 1), (850, 1), (851, 1), (853, 1), (854, 1), (870, 1), (883, 1), (886, 1), (889, 2), (894, 1), (896, 1), (897, 1), (902, 1), (907, 1), (909, 1), (910, 1), (919, 1), (922, 1), (923, 1), (927, 1), (932, 1), (939, 1), (940, 1), (950, 1), (952, 1), (954, 1), (955, 1), (959, 1), (961, 1), (969, 1), (971, 1), (973, 1), (975, 2), (978, 1), (980, 1), (981, 1), (984, 1), (986, 1), (988, 1), (990, 1), (1000, 1)]\n",
      "adventure         198    1.62     1.40    [(6, 1), (9, 1), (11, 1), (14, 1), (17, 1), (22, 1), (24, 1), (30, 1), (32, 1), (40, 1), (44, 1), (48, 1), (59, 1), (60, 1), (61, 1), (62, 1), (64, 1), (67, 1), (71, 1), (73, 1), (94, 1), (102, 1), (107, 1), (110, 1), (111, 1), (115, 1), (117, 1), (119, 1), (136, 1), (138, 1), (147, 1), (152, 1), (156, 1), (159, 1), (169, 1), (178, 1), (179, 1), (180, 1), (192, 1), (194, 1), (206, 1), (210, 1), (214, 1), (220, 2), (224, 1), (227, 1), (231, 1), (232, 1), (243, 1), (246, 1), (248, 1), (263, 1), (268, 1), (271, 1), (274, 1), (282, 1), (301, 1), (302, 1), (305, 1), (307, 1), (321, 1), (324, 1), (326, 1), (330, 1), (331, 1), (333, 1), (340, 1), (344, 1), (349, 1), (358, 1), (362, 1), (367, 1), (368, 1), (369, 1), (377, 1), (378, 1), (379, 1), (390, 1), (400, 1), (403, 1), (407, 1), (410, 1), (416, 1), (427, 1), (459, 1), (470, 1), (471, 1), (474, 1), (478, 1), (480, 1), (483, 1), (494, 1), (497, 1), (498, 1), (499, 2), (500, 1), (503, 1), (507, 1), (508, 1), (514, 1), (515, 1), (517, 1), (523, 1), (533, 1), (536, 1), (538, 1), (541, 1), (544, 1), (550, 1), (553, 1), (554, 1), (565, 1), (567, 1), (577, 1), (579, 1), (583, 1), (584, 1), (593, 1), (597, 1), (600, 1), (605, 1), (610, 1), (619, 1), (624, 1), (626, 1), (634, 1), (635, 1), (639, 1), (643, 1), (646, 2), (648, 1), (652, 1), (673, 1), (676, 1), (678, 1), (682, 2), (687, 1), (693, 1), (705, 1), (710, 1), (712, 1), (714, 1), (723, 1), (726, 1), (731, 1), (738, 1), (740, 1), (741, 1), (742, 1), (745, 1), (747, 1), (750, 1), (752, 1), (756, 1), (757, 1), (762, 1), (772, 1), (782, 1), (798, 1), (799, 1), (808, 1), (822, 1), (823, 1), (829, 1), (840, 1), (841, 1), (844, 1), (852, 1), (855, 1), (857, 1), (862, 1), (866, 1), (874, 1), (882, 1), (885, 1), (888, 1), (892, 1), (893, 1), (899, 1), (903, 1), (910, 1), (913, 1), (915, 1), (920, 1), (921, 2), (928, 1), (945, 1), (948, 1), (957, 1), (958, 1), (964, 1), (965, 1), (967, 1), (983, 1), (985, 1), (987, 1), (992, 1), (993, 1)]\n",
      "action            191    1.65     1.44    [(3, 1), (6, 1), (9, 1), (11, 1), (14, 1), (15, 1), (17, 1), (25, 1), (30, 1), (31, 1), (32, 1), (40, 1), (43, 1), (45, 1), (56, 1), (58, 1), (59, 1), (60, 1), (61, 1), (64, 1), (69, 1), (71, 1), (73, 1), (107, 1), (110, 1), (112, 1), (130, 1), (131, 1), (135, 1), (141, 1), (143, 1), (145, 1), (153, 1), (156, 1), (161, 1), (162, 1), (167, 1), (169, 1), (172, 1), (173, 1), (178, 1), (182, 1), (195, 1), (202, 1), (203, 1), (217, 1), (218, 1), (224, 1), (225, 1), (231, 1), (237, 1), (242, 1), (247, 1), (263, 1), (276, 1), (295, 1), (309, 1), (321, 1), (326, 1), (327, 1), (332, 1), (338, 1), (340, 1), (341, 1), (344, 1), (346, 1), (349, 1), (352, 1), (354, 1), (357, 1), (358, 1), (363, 1), (369, 1), (370, 1), (376, 1), (377, 1), (379, 2), (390, 1), (391, 1), (395, 1), (406, 1), (411, 1), (432, 1), (437, 1), (474, 1), (478, 1), (480, 1), (483, 1), (489, 1), (494, 1), (497, 1), (503, 1), (508, 1), (511, 1), (512, 1), (523, 1), (533, 1), (536, 1), (541, 1), (544, 1), (565, 1), (570, 1), (571, 1), (574, 1), (578, 1), (579, 1), (583, 1), (584, 1), (593, 1), (600, 1), (603, 1), (606, 1), (609, 1), (616, 1), (624, 1), (626, 1), (628, 1), (635, 1), (642, 1), (643, 1), (646, 1), (649, 1), (656, 1), (660, 1), (664, 1), (666, 1), (667, 1), (675, 1), (678, 1), (679, 1), (686, 1), (697, 1), (703, 1), (706, 1), (710, 1), (711, 1), (719, 1), (723, 1), (726, 1), (731, 1), (738, 1), (745, 1), (747, 1), (750, 1), (752, 1), (769, 1), (775, 1), (777, 1), (778, 1), (783, 1), (785, 1), (797, 1), (808, 1), (822, 1), (833, 1), (840, 1), (841, 1), (848, 1), (851, 1), (853, 1), (854, 1), (855, 1), (857, 1), (862, 1), (866, 1), (888, 1), (889, 1), (890, 1), (892, 1), (894, 1), (897, 1), (899, 1), (901, 1), (902, 1), (909, 1), (910, 1), (915, 1), (919, 1), (925, 1), (928, 1), (929, 1), (931, 1), (932, 1), (945, 1), (952, 1), (964, 1), (969, 1), (980, 1), (983, 1), (984, 1), (986, 1)]\n",
      "thriller          137    1.98     1.84    [(20, 1), (29, 1), (34, 1), (38, 1), (42, 1), (50, 1), (68, 1), (70, 1), (82, 1), (85, 1), (88, 1), (104, 1), (106, 1), (111, 1), (119, 1), (120, 1), (126, 1), (146, 1), (164, 1), (165, 1), (172, 1), (182, 1), (187, 1), (188, 1), (197, 1), (200, 1), (204, 1), (205, 1), (211, 1), (221, 1), (233, 1), (245, 1), (249, 1), (256, 1), (276, 1), (284, 1), (290, 1), (294, 1), (306, 1), (307, 1), (310, 1), (327, 1), (336, 1), (338, 1), (339, 1), (354, 1), (356, 1), (362, 1), (363, 1), (365, 1), (369, 1), (370, 1), (394, 1), (401, 1), (416, 1), (421, 1), (456, 1), (463, 1), (475, 1), (489, 1), (512, 1), (513, 1), (516, 1), (524, 1), (528, 1), (545, 1), (549, 1), (556, 1), (557, 1), (571, 1), (602, 2), (609, 1), (613, 1), (616, 1), (642, 1), (649, 1), (650, 1), (655, 1), (667, 1), (671, 1), (694, 1), (696, 1), (701, 1), (713, 1), (715, 1), (725, 1), (726, 1), (746, 1), (752, 1), (754, 1), (765, 1), (773, 1), (776, 1), (778, 1), (779, 1), (792, 1), (793, 1), (796, 1), (803, 1), (825, 1), (827, 1), (828, 1), (830, 1), (835, 1), (845, 1), (846, 1), (848, 1), (852, 1), (854, 1), (860, 1), (862, 1), (864, 1), (865, 1), (879, 1), (891, 1), (900, 1), (901, 1), (912, 1), (914, 1), (927, 1), (930, 1), (933, 1), (939, 1), (940, 1), (943, 1), (949, 1), (955, 1), (959, 1), (960, 1), (961, 1), (962, 1), (964, 1), (980, 1), (981, 1), (984, 1), (994, 1), (1000, 1)]\n",
      "young             132    2.02     1.88    [(29, 1), (35, 1), (36, 1), (47, 1), (50, 1), (52, 1), (106, 1), (147, 1), (151, 1), (153, 1), (154, 1), (155, 1), (159, 2), (168, 1), (170, 1), (196, 1), (197, 1), (198, 1), (202, 1), (204, 1), (212, 1), (214, 1), (215, 1), (220, 1), (231, 2), (240, 1), (258, 1), (260, 1), (266, 1), (275, 1), (276, 1), (280, 1), (285, 1), (295, 1), (298, 1), (300, 1), (311, 1), (317, 1), (326, 1), (333, 2), (341, 1), (351, 1), (364, 1), (367, 1), (368, 1), (372, 1), (380, 1), (385, 1), (389, 1), (390, 1), (393, 1), (402, 1), (407, 1), (410, 1), (411, 1), (418, 1), (426, 1), (429, 1), (437, 1), (443, 1), (465, 1), (476, 1), (482, 1), (486, 1), (491, 1), (499, 1), (501, 1), (505, 1), (507, 1), (518, 1), (532, 1), (542, 1), (543, 1), (559, 1), (579, 1), (582, 1), (586, 1), (587, 1), (591, 1), (599, 1), (604, 1), (612, 1), (626, 1), (627, 1), (638, 2), (640, 1), (643, 1), (646, 1), (647, 1), (659, 1), (661, 1), (670, 1), (673, 1), (682, 1), (708, 1), (713, 1), (715, 1), (722, 1), (723, 1), (724, 1), (725, 1), (735, 1), (755, 1), (757, 1), (759, 1), (764, 1), (765, 1), (781, 1), (786, 1), (787, 1), (794, 1), (799, 1), (814, 1), (830, 1), (833, 1), (835, 1), (858, 1), (865, 1), (869, 1), (886, 1), (889, 1), (902, 1), (904, 1), (910, 1), (917, 1), (920, 1), (921, 1), (935, 1), (937, 1), (957, 1), (959, 1), (996, 2)]\n",
      "man               129    2.04     1.91    [(12, 1), (21, 1), (26, 1), (36, 1), (50, 1), (59, 2), (70, 1), (77, 1), (88, 1), (118, 1), (123, 1), (129, 1), (137, 1), (139, 2), (168, 1), (181, 1), (186, 1), (198, 1), (202, 1), (211, 1), (213, 1), (216, 1), (225, 1), (230, 1), (244, 1), (254, 1), (260, 1), (264, 1), (269, 1), (274, 1), (277, 2), (283, 1), (285, 1), (289, 1), (295, 1), (296, 1), (308, 1), (310, 1), (311, 1), (314, 1), (315, 1), (320, 1), (323, 1), (326, 1), (332, 1), (349, 1), (351, 1), (352, 2), (353, 1), (354, 1), (364, 1), (371, 1), (374, 1), (380, 1), (383, 1), (386, 1), (392, 1), (394, 1), (399, 1), (405, 1), (419, 2), (421, 1), (424, 1), (442, 1), (461, 1), (468, 1), (475, 1), (485, 1), (486, 1), (496, 1), (499, 1), (503, 1), (504, 1), (510, 2), (512, 1), (525, 1), (558, 1), (559, 1), (584, 1), (587, 1), (589, 1), (591, 1), (592, 1), (596, 1), (620, 1), (626, 1), (629, 1), (638, 1), (643, 1), (644, 1), (646, 1), (655, 1), (659, 1), (693, 2), (711, 1), (727, 1), (747, 1), (755, 1), (783, 1), (787, 1), (789, 1), (799, 1), (805, 1), (819, 1), (835, 1), (838, 1), (841, 1), (843, 1), (859, 1), (864, 1), (865, 1), (869, 1), (871, 1), (872, 1), (877, 1), (884, 1), (896, 1), (918, 1), (920, 1), (922, 1), (927, 1), (935, 1), (938, 1), (960, 1), (965, 3), (969, 1), (979, 1), (996, 1), (1000, 2)]\n",
      "romance           126    2.06     1.93    [(12, 1), (27, 1), (46, 1), (51, 1), (53, 1), (95, 1), (96, 1), (100, 1), (118, 2), (120, 1), (121, 1), (144, 1), (167, 1), (184, 1), (185, 1), (195, 1), (196, 1), (200, 1), (215, 1), (234, 1), (238, 1), (241, 1), (250, 1), (252, 1), (254, 1), (259, 1), (260, 1), (261, 1), (265, 1), (266, 1), (311, 1), (312, 1), (313, 1), (315, 2), (317, 1), (319, 1), (320, 1), (335, 1), (342, 1), (345, 1), (351, 1), (355, 1), (364, 1), (372, 1), (380, 1), (397, 1), (408, 1), (415, 1), (422, 1), (428, 1), (431, 1), (441, 1), (447, 1), (453, 1), (455, 1), (465, 1), (467, 1), (468, 2), (479, 1), (482, 1), (484, 1), (491, 1), (505, 1), (509, 1), (521, 2), (525, 1), (534, 1), (542, 1), (548, 2), (552, 1), (560, 1), (563, 1), (564, 1), (565, 1), (586, 1), (591, 1), (592, 1), (599, 1), (618, 1), (621, 1), (625, 1), (629, 1), (632, 1), (638, 1), (648, 1), (653, 1), (654, 1), (662, 1), (665, 1), (691, 1), (707, 1), (716, 1), (722, 1), (727, 1), (730, 1), (732, 1), (735, 1), (737, 1), (744, 1), (753, 1), (755, 1), (761, 1), (774, 1), (787, 1), (804, 1), (807, 1), (836, 1), (858, 1), (871, 1), (872, 1), (874, 1), (875, 1), (886, 1), (904, 1), (906, 1), (908, 1), (930, 1), (936, 1), (937, 1), (963, 1), (966, 1), (968, 1), (972, 1), (976, 1), (996, 1), (998, 1)]\n",
      "family            111    2.19     2.08    [(4, 1), (20, 1), (24, 2), (33, 1), (40, 1), (43, 1), (52, 1), (62, 2), (66, 1), (67, 1), (74, 1), (88, 2), (91, 1), (93, 2), (101, 1), (128, 1), (137, 1), (138, 1), (149, 1), (150, 1), (159, 1), (171, 1), (178, 1), (198, 1), (207, 1), (229, 1), (270, 1), (275, 1), (298, 1), (326, 1), (329, 1), (334, 1), (379, 1), (388, 1), (396, 1), (402, 1), (407, 1), (423, 1), (430, 1), (458, 1), (459, 1), (464, 1), (466, 1), (467, 1), (473, 1), (484, 1), (506, 1), (507, 1), (519, 1), (520, 1), (532, 1), (539, 1), (558, 1), (559, 1), (561, 1), (577, 2), (595, 1), (627, 1), (630, 1), (651, 1), (661, 1), (682, 1), (689, 1), (692, 1), (699, 1), (704, 1), (705, 1), (711, 1), (713, 1), (716, 1), (721, 1), (729, 1), (744, 1), (756, 1), (764, 1), (766, 1), (782, 1), (783, 1), (784, 1), (788, 1), (789, 1), (794, 1), (814, 1), (820, 1), (842, 1), (844, 1), (864, 1), (871, 1), (876, 1), (888, 1), (892, 2), (896, 1), (897, 1), (903, 3), (913, 1), (916, 1), (919, 1), (920, 1), (921, 1), (928, 1), (941, 2), (946, 1), (948, 2), (949, 1), (957, 1), (974, 2), (975, 1), (977, 1), (985, 1), (993, 1), (997, 1)]\n",
      "\n",
      "treasury            1    6.22     6.50    [(19, 1)]\n",
      "desire              3    5.52     5.65    [(12, 1), (448, 1), (735, 1)]\n",
      "francis             3    5.52     5.65    [(665, 1), (809, 1), (891, 1)]\n",
      "remaining           4    5.30     5.40    [(60, 1), (227, 1), (352, 1), (942, 1)]\n",
      "havers              1    6.22     6.50    [(833, 1)]\n",
      "12                  7    4.83     4.89    [(5, 1), (43, 1), (54, 1), (216, 1), (337, 1), (420, 1), (729, 1)]\n",
      "attempts            8    4.71     4.76    [(5, 1), (70, 1), (316, 1), (396, 1), (532, 1), (540, 1), (709, 1), (734, 1)]\n",
      "women              13    4.27     4.29    [(149, 1), (184, 1), (197, 1), (240, 1), (509, 1), (514, 1), (586, 2), (609, 1), (663, 1), (669, 1), (786, 1), (865, 1), (934, 1)]\n",
      "knox                1    6.22     6.50    [(862, 1)]\n",
      "brazil              1    6.22     6.50    [(530, 1)]\n",
      "danes               1    6.22     6.50    [(920, 1)]\n",
      "artists             1    6.22     6.50    [(513, 1)]\n",
      "farahani            1    6.22     6.50    [(350, 1)]\n",
      "capital             1    6.22     6.50    [(21, 1)]\n",
      "manipulative        2    5.81     5.99    [(29, 1), (315, 1)]\n"
     ]
    }
   ],
   "source": [
    "# print vocabulary with df and idf\n",
    "print('term               df     idf idf_bm25    postings')\n",
    "print('-' * 100)\n",
    "for term, item in sorted(vocabulary.items(), key=lambda t: -t[1]['df'])[:10]:\n",
    "    print(\"{term:16} {df:>4d} {idf:>7.2f} {idf_bm25:>8.2f}    {postings}\".format(term=term.ljust(10), df=item['df'], idf=item['idf'], idf_bm25=item['idf_bm25'], postings=index[term]))\n",
    "print()\n",
    "for term, item in random.sample(list(vocabulary.items()), 15):\n",
    "    print(\"{term:16} {df:>4d} {idf:>7.2f} {idf_bm25:>8.2f}    {postings}\".format(term=term.ljust(10), df=item['df'], idf=item['idf'], idf_bm25=item['idf_bm25'], postings=index[term]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id |  len     norm   vector\n",
      "----------------------------------------------------------------------------------------------------\n",
      " 397 |   18    20.08   {'andie': 1, 'bill': 1, 'chris': 1, 'comedy': 1, 'day': 2, 'elliott': 1, 'fantasy': 1, 'finds': 1, 'groundhog': 1, 'inexplicably': 1, 'living': 1, 'macdowell': 1, 'murray': 1, 'romance': 1, 'stephen': 1, 'tobolowsky': 1, 'weatherman': 1}\n",
      " 677 |   27    27.09   {'activists': 1, 'agents': 1, 'arrive': 1, 'b': 1, 'brad': 1, 'burning': 1, 'civil': 1, 'crime': 1, 'dafoe': 1, 'different': 1, 'disappearance': 1, 'dourif': 1, 'drama': 1, 'f': 1, 'frances': 1, 'gene': 1, 'hackman': 1, 'history': 1, 'investigate': 1, 'mcdormand': 1, 'mississippi': 2, 'rights': 1, 'styles': 1, 'two': 1, 'wildly': 1, 'willem': 1}\n",
      " 877 |   21    22.89   {'becomes': 1, 'becoming': 1, 'claude': 1, 'fi': 1, 'finds': 1, 'gloria': 1, 'harrigan': 1, 'henry': 1, 'horror': 1, 'insane': 1, 'invisible': 2, 'man': 1, 'murderously': 1, 'rains': 1, 'sci': 1, 'scientist': 1, 'stuart': 1, 'travers': 1, 'way': 1, 'william': 1}\n",
      " 127 |   34    32.78   {'abel': 1, 'alfred': 1, 'brigitte': 1, 'city': 3, 'class': 2, 'coming': 1, 'differences': 1, 'divided': 1, 'drama': 1, 'falls': 1, 'fi': 1, 'fr√∂hlich': 1, 'futuristic': 1, 'gustav': 1, 'helm': 1, 'klein': 1, 'love': 1, 'mastermind': 1, 'mediate': 1, 'metropolis': 1, 'planners': 1, 'predicts': 1, 'prophet': 1, 'rogge': 1, 'rudolf': 1, 'savior': 1, 'sci': 1, 'sharply': 1, 'son': 1, 'working': 2}\n",
      " 684 |   23    24.77   {'ally': 1, 'breakfast': 1, 'club': 1, 'comedy': 1, 'common': 1, 'detention': 1, 'discover': 1, 'drama': 1, 'emilio': 1, 'estevez': 1, 'five': 1, 'high': 1, 'judd': 1, 'lot': 1, 'meet': 1, 'molly': 1, 'nelson': 1, 'ringwald': 1, 'saturday': 1, 'school': 1, 'sheedy': 1, 'students': 1, 'thought': 1}\n",
      " 836 |   23    24.09   {'1935': 1, 'aiello': 1, 'cairo': 1, 'character': 1, 'comedy': 1, 'daniels': 1, 'danny': 1, 'fantasy': 1, 'farrow': 1, 'irving': 1, 'jeff': 1, 'jersey': 1, 'metzman': 1, 'mia': 1, 'movie': 1, 'new': 1, 'purple': 1, 'real': 1, 'romance': 1, 'rose': 1, 'screen': 1, 'walks': 1, 'world': 1}\n",
      " 323 |   17    20.48   {'ayushmann': 1, 'badhaai': 1, 'comedy': 1, 'drama': 1, 'embarrassed': 1, 'finds': 1, 'gajraj': 1, 'gupta': 1, 'ho': 1, 'khurrana': 1, 'malhotra': 1, 'man': 1, 'mother': 1, 'neena': 1, 'pregnant': 1, 'rao': 1, 'sanya': 1}\n",
      " 860 |   24    24.39   {'boyfriend': 1, 'catherine': 1, 'deneuve': 1, 'depression': 1, 'disapproves': 1, 'drama': 1, 'fraser': 1, 'furneaux': 1, 'hendry': 1, 'horrific': 1, 'horror': 1, 'ian': 1, 'john': 1, 'rape': 1, 'repulsed': 1, 'repulsion': 1, 'sex': 1, 'sinks': 1, 'sister': 1, 'thriller': 1, 'violence': 1, 'visions': 1, 'woman': 1, 'yvonne': 1}\n",
      " 225 |   28    28.39   {'aamir': 1, 'action': 1, 'anupam': 1, 'astounding': 1, 'bashir': 1, 'career': 1, 'case': 2, 'continues': 1, 'crime': 1, 'day': 1, 'drama': 1, 'filed': 1, 'haunt': 1, 'jimmy': 1, 'kher': 1, 'man': 1, 'memories': 1, 'naseeruddin': 1, 'never': 1, 'officer': 1, 'police': 1, 'reminisces': 1, 'retiring': 1, 'shah': 1, 'sheirgill': 1, 'wednesday': 2}\n",
      " 868 |   25    25.11   {'alien': 1, 'body': 1, 'community': 1, 'dana': 1, 'doctor': 1, 'donovan': 1, 'drama': 1, 'duplicates': 1, 'emotionless': 1, 'fi': 1, 'gates': 1, 'horror': 1, 'invasion': 1, 'kevin': 1, 'king': 1, 'larry': 1, 'learns': 1, 'mccarthy': 1, 'population': 1, 'replaced': 1, 'sci': 1, 'small': 1, 'snatchers': 1, 'town': 1, 'wynter': 1}\n",
      " 704 |   29    27.60   {'agrees': 1, 'audrey': 1, 'doolittle': 1, 'drama': 1, 'eliza': 1, 'fair': 1, 'family': 1, 'flower': 1, 'girl': 1, 'harrison': 1, 'henry': 1, 'hepburn': 1, 'higgins': 1, 'high': 1, 'holloway': 1, 'hyde': 1, 'lady': 1, 'make': 1, 'musical': 1, 'phonetics': 1, 'presentable': 1, 'professor': 1, 'rex': 1, 'snobbish': 1, 'society': 1, 'stanley': 1, 'wager': 1, 'white': 1, 'wilfrid': 1}\n",
      " 248 |   27    25.50   {'aamir': 1, 'adventure': 1, 'british': 1, 'cricket': 1, 'drama': 1, 'future': 1, 'game': 1, 'gracy': 1, 'india': 2, 'khan': 1, 'lagaan': 1, 'musical': 1, 'people': 1, 'rachel': 1, 'raghuvir': 1, 'rulers': 1, 'ruthless': 1, 'shelley': 1, 'singh': 1, 'small': 1, 'stake': 1, 'time': 1, 'upon': 1, 'victorian': 1, 'village': 1, 'yadav': 1}\n",
      " 802 |   31    27.39   {'acts': 1, 'adams': 1, 'baker': 1, 'comedy': 1, 'connection': 1, 'desperate': 1, 'disturbing': 1, 'drama': 1, 'dylan': 1, 'engaging': 1, 'find': 1, 'go': 1, 'happiness': 1, 'hoffman': 1, 'human': 1, 'individuals': 1, 'intertwine': 1, 'jane': 1, 'jon': 1, 'lives': 2, 'lovitz': 1, 'might': 1, 'philip': 1, 'search': 1, 'several': 1, 'seymour': 1, 'society': 1, 'unique': 1, 'ways': 1, 'whole': 1}\n",
      " 791 |   33    28.56   {'160': 1, 'armed': 1, 'bana': 1, 'battle': 1, 'black': 1, 'capture': 1, 'desperate': 1, 'drama': 1, 'drop': 1, 'elite': 1, 'eric': 1, 'ewan': 1, 'find': 1, 'force': 1, 'hartnett': 1, 'hawk': 1, 'heavily': 1, 'history': 1, 'josh': 1, 'large': 1, 'lieutenants': 1, 'mcgregor': 1, 'renegade': 1, 'sizemore': 1, 'soldiers': 1, 'somalia': 1, 'somalis': 1, 'tom': 1, 'top': 1, 'two': 1, 'u': 1, 'war': 1, 'warlord': 1}\n",
      "  78 |   24    25.01   {'becomes': 1, 'chauffeur': 1, 'company': 1, 'crime': 1, 'drama': 1, 'executive': 1, 'extortion': 1, 'held': 1, 'jigoku': 1, 'kagawa': 1, 'kidnapped': 1, 'ky√¥ko': 1, 'mifune': 1, 'mystery': 1, 'nakadai': 1, 'ransom': 1, 'sada': 1, 'shoe': 1, 'son': 1, 'tatsuya': 1, 'tengoku': 1, 'toshir√¥': 1, 'victim': 1, 'yutaka': 1}\n",
      " 115 |   32    28.69   {'2001': 1, '9000': 1, 'adventure': 1, 'artifact': 1, 'beneath': 1, 'buried': 1, 'daniel': 1, 'discovering': 1, 'dullea': 1, 'fi': 1, 'find': 1, 'gary': 1, 'h': 1, 'help': 1, 'intelligent': 1, 'keir': 1, 'l': 1, 'lockwood': 1, 'lunar': 1, 'mankind': 1, 'mysterious': 1, 'odyssey': 1, 'origins': 1, 'quest': 1, 'richter': 1, 'sci': 1, 'sets': 1, 'space': 1, 'supercomputer': 1, 'surface': 1, 'sylvester': 1, 'william': 1}\n",
      " 947 |   31    28.01   {'ana': 1, 'attractive': 1, 'bernal': 1, 'boys': 1, 'cacho': 1, 'daniel': 1, 'drama': 1, 'embark': 1, 'friendship': 1, 'gael': 1, 'garc√≠a': 1, 'gim√©nez': 1, 'learn': 1, 'life': 1, 'l√≥pez': 1, 'mam√°': 1, 'maribel': 1, 'mercado': 1, 'mexico': 1, 'older': 1, 'road': 1, 'sex': 1, 'tambi√©n': 1, 'teenage': 1, 'thing': 1, 'trip': 1, 'tu': 1, 'two': 2, 'verd√∫': 1, 'woman': 1}\n",
      " 187 |   25    24.79   {'carl': 1, 'chez': 1, 'crime': 2, 'darcey': 1, 'drama': 1, 'du': 1, 'element': 1, 'four': 1, 'hommes': 1, 'human': 1, 'intervenes': 1, 'janine': 1, 'jean': 1, 'les': 1, 'manuel': 1, 'men': 1, 'm√∂hner': 1, 'perfect': 1, 'plan': 1, 'rififi': 1, 'robert': 1, 'servais': 1, 'technically': 1, 'thriller': 1}\n",
      " 867 |   25    25.98   {'accident': 1, 'alexandre': 1, 'alida': 1, 'brasseur': 1, 'causes': 1, 'daughter': 1, 'disfigured': 1, 'drama': 1, 'extremes': 1, 'face': 1, 'give': 1, 'goes': 1, 'horror': 1, 'juliette': 1, 'leaves': 1, 'les': 1, 'mayniel': 1, 'new': 1, 'pierre': 1, 'rignault': 1, 'sans': 1, 'surgeon': 1, 'valli': 1, 'visage': 1, 'yeux': 1}\n",
      " 832 |   17    20.56   {'biography': 1, 'chen': 1, 'china': 1, 'drama': 1, 'emperor': 2, 'final': 1, 'history': 1, 'joan': 1, 'john': 1, 'last': 1, 'lone': 1, 'peter': 1, 'ruocheng': 1, 'story': 1, 'toole': 1, 'ying': 1}\n",
      " 386 |   23    22.35   {'biography': 1, 'brother': 1, 'carpenter': 1, 'drama': 1, 'farnsworth': 1, 'galloway': 1, 'heitz': 1, 'ill': 1, 'jane': 1, 'joseph': 1, 'journey': 1, 'lawnmower': 1, 'long': 1, 'makes': 1, 'man': 1, 'mend': 1, 'old': 1, 'relationship': 1, 'richard': 1, 'sissy': 1, 'spacek': 1, 'story': 1, 'straight': 1}\n",
      "   3 |   32    28.18   {'aaron': 1, 'ability': 1, 'accept': 1, 'action': 1, 'bale': 1, 'batman': 1, 'caine': 1, 'chaos': 1, 'christian': 1, 'crime': 1, 'dark': 1, 'drama': 1, 'eckhart': 1, 'fight': 1, 'gotham': 1, 'greatest': 1, 'havoc': 1, 'heath': 1, 'injustice': 1, 'joker': 1, 'knight': 1, 'known': 1, 'ledger': 1, 'menace': 1, 'michael': 1, 'must': 1, 'one': 1, 'people': 1, 'physical': 1, 'psychological': 1, 'tests': 1, 'wreaks': 1}\n",
      " 216 |   29    25.24   {'12': 1, 'abducted': 1, 'antebellum': 1, 'biography': 1, 'black': 1, 'brad': 1, 'chiwetel': 1, 'drama': 1, 'ejiofor': 1, 'fassbender': 1, 'free': 1, 'history': 1, 'kenneth': 1, 'man': 1, 'michael': 2, 'new': 1, 'northup': 1, 'pitt': 1, 'slave': 1, 'slavery': 1, 'sold': 1, 'solomon': 1, 'states': 1, 'united': 1, 'upstate': 1, 'williams': 1, 'years': 1, 'york': 1}\n",
      " 335 |   22    24.77   {'age': 1, 'based': 1, 'boy': 1, 'coming': 1, 'drama': 1, 'gully': 1, 'lives': 1, 'mumbai': 1, 'music': 1, 'nakul': 1, 'raaz': 1, 'ranveer': 1, 'rappers': 1, 'romance': 1, 'roshan': 1, 'sahdev': 1, 'singh': 1, 'story': 1, 'street': 1, 'varma': 1, 'vijay': 2}\n",
      " 713 |   30    27.08   {'authorities': 1, 'begins': 1, 'carey': 1, 'comes': 1, 'cotten': 1, 'doubt': 1, 'fact': 1, 'family': 1, 'favorite': 1, 'film': 1, 'girl': 1, 'henry': 1, 'joseph': 1, 'killer': 1, 'macdonald': 1, 'merry': 1, 'noir': 1, 'overjoyed': 1, 'shadow': 1, 'slowly': 1, 'sought': 1, 'suspect': 1, 'teresa': 1, 'thriller': 1, 'travers': 1, 'uncle': 1, 'visit': 1, 'widow': 1, 'wright': 1, 'young': 1}\n"
     ]
    }
   ],
   "source": [
    "# print a few documents\n",
    "print('  id |  len     norm   vector')\n",
    "print('-' * 100)\n",
    "for doc_id in random.sample(range(1, len(documents) + 1), 25):\n",
    "    print(\"{id:>4} | {len:>4d} {norm:>8.2f}   {vector}\".format(id=doc_id, len=documents[doc_id]['len'], norm=documents[doc_id]['norm'], vector=str(documents[doc_id]['vector'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
